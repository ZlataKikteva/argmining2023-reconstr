{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41742c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T20:59:06.753988Z",
     "start_time": "2023-09-07T20:59:06.741986Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv  \n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 4\n",
    "CONFIGS = [\n",
    "['L_node_1', 'L_node_2'],\n",
    "['context_L_node', 'L_node_1', 'L_node_2'],\n",
    "['I_node_1', 'I_node_2'],\n",
    "[ 'context_I_node', 'I_node_1', 'I_node_2']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e44fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T20:59:07.219130Z",
     "start_time": "2023-09-07T20:59:07.213450Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_X_and_Y(config, data):\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    combined_text = data[config[0]].astype(str)\n",
    "    for column in config[1:]:\n",
    "        combined_text += ' ' + data[column].astype(str)\n",
    "    tokenizer.fit_on_texts(combined_text)\n",
    "    X = tokenizer.texts_to_sequences(combined_text.values)\n",
    "    X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    y = pd.get_dummies(data['prop_rel']).values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19790885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T20:59:07.656502Z",
     "start_time": "2023-09-07T20:59:07.640583Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(X):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf466b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T20:59:08.167827Z",
     "start_time": "2023-09-07T20:59:08.157819Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix_and_fscore(Y_predicted, y_test, config):\n",
    "    y_pred = []\n",
    "    for subarr in Y_predicted:\n",
    "        max_index = np.argmax(subarr)\n",
    "        subarr_output = np.zeros_like(subarr)\n",
    "        subarr_output[max_index] = int(1)\n",
    "        y_pred.append(subarr_output)\n",
    "\n",
    "    y_pred = np.array(y_pred).tolist()\n",
    "    y_pred = [[int(num) for num in arr] for arr in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    f_score = f1_score(y_true, y_pred, average='macro') \n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    matrix = ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "    \n",
    "    config = [entry.split()[0] for entry in config]\n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae66a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T21:12:36.481794Z",
     "start_time": "2023-09-07T20:59:09.160419Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('path\\dataQT30.csv')\n",
    "test_data = pd.read_csv('path\\dataQT31-40.csv')   \n",
    "\n",
    "with open('path\\results\\LSTM_results.csv', 'w', encoding='UTF8') as file:\n",
    "\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Configuration', 'Batches', 'Epochs', 'F-score'])\n",
    "\n",
    "    for config in CONFIGS:\n",
    "        print('Now testing model with config: ' + str(config) + ', batch_size: ' + str(BATCH_SIZE) + ', epochs: ' + str(EPOCHS))\n",
    "\n",
    "        X_train, y_train = create_X_and_Y(config, train_data)\n",
    "        X_test, y_test = create_X_and_Y(config, test_data)\n",
    "\n",
    "        model = create_model(X_train)\n",
    "\n",
    "        history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1)\n",
    "        Y_predicted = model.predict(X_test)\n",
    "        f_score = create_confusion_matrix_and_fscore(Y_predicted, y_test, config)\n",
    "        writer.writerow([config, BATCH_SIZE, EPOCHS, f_score])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
